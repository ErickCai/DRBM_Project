{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/rbm/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f14265b98016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m \u001b[0mrbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRBM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-f14265b98016>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_visible, num_hidden, visible_unit_type, main_dir, model_name, gibbs_sampling_steps, learning_rate, batch_size, num_epochs, stddev, verbose)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_data_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-f14265b98016>\u001b[0m in \u001b[0;36m_create_data_directories\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/rbm/'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import zconfig\n",
    "import utils\n",
    "\n",
    "\n",
    "class RBM(object):\n",
    "\n",
    "    \"\"\" Restricted Boltzmann Machine implementation using TensorFlow.\n",
    "    The interface of the class is sklearn-like.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_visible, num_hidden, visible_unit_type='bin', main_dir='rbm', model_name='rbm_model',\n",
    "                 gibbs_sampling_steps=1, learning_rate=0.01, batch_size=10, num_epochs=10, stddev=0.1, verbose=0):\n",
    "\n",
    "        \"\"\"\n",
    "        :param num_visible: number of visible units\n",
    "        :param num_hidden: number of hidden units\n",
    "        :param visible_unit_type: type of the visible units (binary or gaussian)\n",
    "        :param main_dir: main directory to put the models, data and summary directories\n",
    "        :param model_name: name of the model, used to save data\n",
    "        :param gibbs_sampling_steps: optional, default 1\n",
    "        :param learning_rate: optional, default 0.01\n",
    "        :param batch_size: optional, default 10\n",
    "        :param num_epochs: optional, default 10\n",
    "        :param stddev: optional, default 0.1. Ignored if visible_unit_type is not 'gauss'\n",
    "        :param verbose: level of verbosity. optional, default 0\n",
    "        \"\"\"\n",
    "\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.visible_unit_type = visible_unit_type\n",
    "        self.main_dir = main_dir\n",
    "        self.model_name = model_name\n",
    "        self.gibbs_sampling_steps = gibbs_sampling_steps\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.stddev = stddev\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.models_dir, self.data_dir, self.summary_dir = self._create_data_directories()\n",
    "        self.model_path = self.models_dir + self.model_name\n",
    "\n",
    "        self.W = None\n",
    "        self.bh_ = None\n",
    "        self.bv_ = None\n",
    "\n",
    "        self.w_upd8 = None\n",
    "        self.bh_upd8 = None\n",
    "        self.bv_upd8 = None\n",
    "\n",
    "        self.encode = None\n",
    "\n",
    "        self.loss_function = None\n",
    "\n",
    "        self.input_data = None\n",
    "        self.hrand = None\n",
    "        self.vrand = None\n",
    "        self.validation_size = None\n",
    "\n",
    "        self.tf_merged_summaries = None\n",
    "        self.tf_summary_writer = None\n",
    "        self.tf_session = None\n",
    "        self.tf_saver = None\n",
    "\n",
    "    def fit(self, train_set, validation_set=None, restore_previous_model=False):\n",
    "\n",
    "        \"\"\" Fit the model to the training data.\n",
    "        :param train_set: training set\n",
    "        :param validation_set: validation set. optional, default None\n",
    "        :param restore_previous_model:\n",
    "                    if true, a previous trained model\n",
    "                    with the same name of this model is restored from disk to continue training.\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "\n",
    "        if validation_set is not None:\n",
    "            self.validation_size = validation_set.shape[0]\n",
    "\n",
    "        self._build_model()\n",
    "\n",
    "        with tf.Session() as self.tf_session:\n",
    "\n",
    "            self._initialize_tf_utilities_and_ops(restore_previous_model)\n",
    "            self._train_model(train_set, validation_set)\n",
    "            self.tf_saver.save(self.tf_session, self.model_path)\n",
    "\n",
    "    def _initialize_tf_utilities_and_ops(self, restore_previous_model):\n",
    "\n",
    "        \"\"\" Initialize TensorFlow operations: summaries, init operations, saver, summary_writer.\n",
    "        Restore a previously trained model if the flag restore_previous_model is true.\n",
    "        \"\"\"\n",
    "\n",
    "        self.tf_merged_summaries = tf.merge_all_summaries()\n",
    "        init_op = tf.initialize_all_variables()\n",
    "        self.tf_saver = tf.train.Saver()\n",
    "\n",
    "        self.tf_session.run(init_op)\n",
    "\n",
    "        if restore_previous_model:\n",
    "            self.tf_saver.restore(self.tf_session, self.model_path)\n",
    "\n",
    "        self.tf_summary_writer = tf.train.SummaryWriter(self.summary_dir, self.tf_session.graph_def)\n",
    "\n",
    "    def _train_model(self, train_set, validation_set):\n",
    "\n",
    "        \"\"\" Train the model.\n",
    "        :param train_set: training set\n",
    "        :param validation_set: validation set. optional, default None\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(self.num_epochs):\n",
    "            self._run_train_step(train_set)\n",
    "\n",
    "            if validation_set is not None:\n",
    "                self._run_validation_error_and_summaries(i, validation_set)\n",
    "\n",
    "    def _run_train_step(self, train_set):\n",
    "\n",
    "        \"\"\" Run a training step. A training step is made by randomly shuffling the training set,\n",
    "        divide into batches and run the variable update nodes for each batch.\n",
    "        :param train_set: training set\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "\n",
    "        np.random.shuffle(train_set)\n",
    "\n",
    "        batches = [_ for _ in utils.gen_batches(train_set, self.batch_size)]\n",
    "        updates = [self.w_upd8, self.bh_upd8, self.bv_upd8]\n",
    "\n",
    "        for batch in batches:\n",
    "            self.tf_session.run(updates, feed_dict=self._create_feed_dict(batch))\n",
    "\n",
    "    def _run_validation_error_and_summaries(self, epoch, validation_set):\n",
    "\n",
    "        \"\"\" Run the summaries and error computation on the validation set.\n",
    "        :param epoch: current epoch\n",
    "        :param validation_set: validation data\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "\n",
    "        result = self.tf_session.run([self.tf_merged_summaries, self.loss_function],\n",
    "                                     feed_dict=self._create_feed_dict(validation_set))\n",
    "\n",
    "        summary_str = result[0]\n",
    "        err = result[1]\n",
    "\n",
    "        self.tf_summary_writer.add_summary(summary_str, 1)\n",
    "\n",
    "        if self.verbose == 1:\n",
    "            print(\"Validation cost at step %s: %s\" % (epoch, err))\n",
    "\n",
    "    def _create_feed_dict(self, data):\n",
    "\n",
    "        \"\"\" Create the dictionary of data to feed to TensorFlow's session during training.\n",
    "        :param data: training/validation set batch\n",
    "        :return: dictionary(self.input_data: data, self.hrand: random_uniform, self.vrand: random_uniform)\n",
    "        \"\"\"\n",
    "\n",
    "        return {\n",
    "            self.input_data: data,\n",
    "            self.hrand: np.random.rand(data.shape[0], self.num_hidden),\n",
    "            self.vrand: np.random.rand(data.shape[0], self.num_visible)\n",
    "        }\n",
    "\n",
    "    def _build_model(self):\n",
    "\n",
    "        \"\"\" Build the Restricted Boltzmann Machine model in TensorFlow.\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "\n",
    "        self.input_data, self.hrand, self.vrand = self._create_placeholders()\n",
    "        self.W, self.bh_, self.bv_ = self._create_variables()\n",
    "\n",
    "        hprobs0, hstates0, vprobs, hprobs1, hstates1 = self.gibbs_sampling_step(self.input_data)\n",
    "        positive = self.compute_positive_association(self.input_data, hprobs0, hstates0)\n",
    "\n",
    "        nn_input = vprobs\n",
    "\n",
    "        for step in range(self.gibbs_sampling_steps - 1):\n",
    "            hprobs, hstates, vprobs, hprobs1, hstates1 = self.gibbs_sampling_step(nn_input)\n",
    "            nn_input = vprobs\n",
    "\n",
    "        negative = tf.matmul(tf.transpose(vprobs), hprobs1)\n",
    "\n",
    "        self.encode = hprobs1  # encoded data, used by the transform method\n",
    "\n",
    "        self.w_upd8 = self.W.assign_add(self.learning_rate * (positive - negative))\n",
    "        self.bh_upd8 = self.bh_.assign_add(self.learning_rate * tf.reduce_mean(hprobs0 - hprobs1, 0))\n",
    "        self.bv_upd8 = self.bv_.assign_add(self.learning_rate * tf.reduce_mean(self.input_data - vprobs, 0))\n",
    "\n",
    "        self.loss_function = tf.sqrt(tf.reduce_mean(tf.square(self.input_data - vprobs)))\n",
    "        _ = tf.scalar_summary(\"cost\", self.loss_function)\n",
    "\n",
    "    def _create_placeholders(self):\n",
    "\n",
    "        \"\"\" Create the TensorFlow placeholders for the model.\n",
    "        :return: tuple(input(shape(None, num_visible)),\n",
    "                       hrand(shape(None, num_hidden))\n",
    "                       vrand(shape(None, num_visible)))\n",
    "        \"\"\"\n",
    "\n",
    "        x = tf.placeholder('float', [None, self.num_visible], name='x-input')\n",
    "        hrand = tf.placeholder('float', [None, self.num_hidden], name='hrand')\n",
    "        vrand = tf.placeholder('float', [None, self.num_visible], name='vrand')\n",
    "\n",
    "        return x, hrand, vrand\n",
    "\n",
    "    def _create_variables(self):\n",
    "\n",
    "        \"\"\" Create the TensorFlow variables for the model.\n",
    "        :return: tuple(weights(shape(num_visible, num_hidden),\n",
    "                       hidden bias(shape(num_hidden)),\n",
    "                       visible bias(shape(num_visible)))\n",
    "        \"\"\"\n",
    "\n",
    "        W = tf.Variable(tf.random_normal((self.num_visible, self.num_hidden), mean=0.0, stddev=0.01), name='weights')\n",
    "        bh_ = tf.Variable(tf.zeros([self.num_hidden]), name='hidden-bias')\n",
    "        bv_ = tf.Variable(tf.zeros([self.num_visible]), name='visible-bias')\n",
    "\n",
    "        return W, bh_, bv_\n",
    "\n",
    "    def gibbs_sampling_step(self, visible):\n",
    "\n",
    "        \"\"\" Performs one step of gibbs sampling.\n",
    "        :param visible: activations of the visible units\n",
    "        :return: tuple(hidden probs, hidden states, visible probs,\n",
    "                       new hidden probs, new hidden states)\n",
    "        \"\"\"\n",
    "\n",
    "        hprobs, hstates = self.sample_hidden_from_visible(visible)\n",
    "        vprobs = self.sample_visible_from_hidden(hprobs)\n",
    "        hprobs1, hstates1 = self.sample_hidden_from_visible(vprobs)\n",
    "\n",
    "        return hprobs, hstates, vprobs, hprobs1, hstates1\n",
    "\n",
    "    def sample_hidden_from_visible(self, visible):\n",
    "\n",
    "        \"\"\" Sample the hidden units from the visible units.\n",
    "        This is the Positive phase of the Contrastive Divergence algorithm.\n",
    "        :param visible: activations of the visible units\n",
    "        :return: tuple(hidden probabilities, hidden binary states)\n",
    "        \"\"\"\n",
    "\n",
    "        hprobs = tf.nn.sigmoid(tf.matmul(visible, self.W) + self.bh_)\n",
    "        hstates = utils.sample_prob(hprobs, self.hrand)\n",
    "\n",
    "        return hprobs, hstates\n",
    "\n",
    "    def sample_visible_from_hidden(self, hidden):\n",
    "\n",
    "        \"\"\" Sample the visible units from the hidden units.\n",
    "        This is the Negative phase of the Contrastive Divergence algorithm.\n",
    "        :param hidden: activations of the hidden units\n",
    "        :return: visible probabilities\n",
    "        \"\"\"\n",
    "\n",
    "        visible_activation = tf.matmul(hidden, tf.transpose(self.W)) + self.bv_\n",
    "\n",
    "        if self.visible_unit_type == 'bin':\n",
    "            vprobs = tf.nn.sigmoid(visible_activation)\n",
    "\n",
    "        elif self.visible_unit_type == 'gauss':\n",
    "            vprobs = tf.truncated_normal((1, self.num_visible), mean=visible_activation, stddev=self.stddev)\n",
    "\n",
    "        else:\n",
    "            vprobs = None\n",
    "\n",
    "        return vprobs\n",
    "\n",
    "    def compute_positive_association(self, visible, hidden_probs, hidden_states):\n",
    "\n",
    "        \"\"\" Compute positive associations between visible and hidden units.\n",
    "        :param visible: visible units\n",
    "        :param hidden_probs: hidden units probabilities\n",
    "        :param hidden_states: hidden units states\n",
    "        :return: positive association = dot(visible.T, hidden)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.visible_unit_type == 'bin':\n",
    "            positive = tf.matmul(tf.transpose(visible), hidden_states)\n",
    "\n",
    "        elif self.visible_unit_type == 'gauss':\n",
    "            positive = tf.matmul(tf.transpose(visible), hidden_probs)\n",
    "\n",
    "        else:\n",
    "            positive = None\n",
    "\n",
    "        return positive\n",
    "\n",
    "    def _create_data_directories(self):\n",
    "\n",
    "        \"\"\" Create the three directories for storing respectively the models,\n",
    "        the data generated by training and the TensorFlow's summaries.\n",
    "        :return: tuple of strings(models_dir, data_dir, summary_dir)\n",
    "        \"\"\"\n",
    "\n",
    "        self.main_dir = self.main_dir + '/' if self.main_dir[-1] != '/' else self.main_dir\n",
    "\n",
    "        models_dir = config.models_dir + self.main_dir\n",
    "        data_dir = config.data_dir + self.main_dir\n",
    "        summary_dir = config.summary_dir + self.main_dir\n",
    "\n",
    "        for d in [models_dir, data_dir, summary_dir]:\n",
    "            if not os.path.isdir(d):\n",
    "                os.mkdir(d)\n",
    "\n",
    "        return models_dir, data_dir, summary_dir\n",
    "\n",
    "    def transform(self, data, name='train', save=False):\n",
    "\n",
    "        \"\"\" Transform data according to the model.\n",
    "        :type data: array_like\n",
    "        :param data: Data to transform\n",
    "        :type name: string, default 'train'\n",
    "        :param name: Identifier for the data that is being encoded\n",
    "        :type save: boolean, default 'False'\n",
    "        :param save: If true, save data to disk\n",
    "        :return: transformed data\n",
    "        \"\"\"\n",
    "\n",
    "        with tf.Session() as self.tf_session:\n",
    "\n",
    "            self.tf_saver.restore(self.tf_session, self.model_path)\n",
    "\n",
    "            encoded_data = self.encode.eval(self._create_feed_dict(data))\n",
    "\n",
    "            if save:\n",
    "                np.save(self.data_dir + self.model_name + '-' + name, encoded_data)\n",
    "\n",
    "            return encoded_data\n",
    "\n",
    "    def load_model(self, shape, gibbs_sampling_steps, model_path):\n",
    "\n",
    "        \"\"\" Load a trained model from disk. The shape of the model\n",
    "        (num_visible, num_hidden) and the number of gibbs sampling steps\n",
    "        must be known in order to restore the model.\n",
    "        :param shape: tuple(num_visible, num_hidden)\n",
    "        :param gibbs_sampling_steps:\n",
    "        :param model_path:\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "\n",
    "        self.num_visible, self.num_hidden = shape[0], shape[1]\n",
    "        self.gibbs_sampling_steps = gibbs_sampling_steps\n",
    "\n",
    "        self._build_model()\n",
    "\n",
    "        init_op = tf.initialize_all_variables()\n",
    "        self.tf_saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as self.tf_session:\n",
    "\n",
    "            self.tf_session.run(init_op)\n",
    "            self.tf_saver.restore(self.tf_session, model_path)\n",
    "\n",
    "    def get_model_parameters(self):\n",
    "\n",
    "        \"\"\" Return the model parameters in the form of numpy arrays.\n",
    "        :return: model parameters\n",
    "        \"\"\"\n",
    "\n",
    "        with tf.Session() as self.tf_session:\n",
    "\n",
    "            self.tf_saver.restore(self.tf_session, self.model_path)\n",
    "\n",
    "            return {\n",
    "                'W': self.W.eval(),\n",
    "                'bh_': self.bh_.eval(),\n",
    "                'bv_': self.bv_.eval()\n",
    "            }\n",
    "\n",
    "    def get_weights_as_images(self, width, height, outdir='img/', n_images=10, img_type='grey'):\n",
    "\n",
    "        \"\"\" Create and save the weights of the hidden units with respect to the\n",
    "        visible units as images.\n",
    "        :param width:\n",
    "        :param height:\n",
    "        :param outdir:\n",
    "        :param n_images:\n",
    "        :param img_type:\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "\n",
    "        outdir = self.data_dir + outdir\n",
    "\n",
    "        with tf.Session() as self.tf_session:\n",
    "\n",
    "            self.tf_saver.restore(self.tf_session, self.model_path)\n",
    "\n",
    "            weights = self.W.eval()\n",
    "\n",
    "            perm = np.random.permutation(self.num_hidden)[:n_images]\n",
    "\n",
    "            for p in perm:\n",
    "                w = np.array([i[p] for i in weights])\n",
    "                image_path = outdir + self.model_name + '_{}.png'.format(p)\n",
    "                utils.gen_image(w, width, height, image_path, img_type)\n",
    "\n",
    "                \n",
    "                \n",
    "rbm = RBM(4,5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
